diff --git a/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStep.scala b/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStep.scala
index fa4e40adab..b8ee7427b7 100644
--- a/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStep.scala
+++ b/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStep.scala
@@ -200,7 +200,6 @@ private[spark] class BasicExecutorFeatureStep(
       .withImagePullPolicy(kubernetesConf.imagePullPolicy)
       .editOrNewResources()
         .addToRequests("memory", executorMemoryQuantity)
-        .addToLimits("memory", executorMemoryQuantity)
         .addToRequests("cpu", executorCpuQuantity)
         .addToLimits(executorResourceQuantities.asJava)
         .endResources()
diff --git a/resource-managers/kubernetes/core/src/test/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStepSuite.scala b/resource-managers/kubernetes/core/src/test/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStepSuite.scala
index 1aa34aa7e9..953b37cf9d 100644
--- a/resource-managers/kubernetes/core/src/test/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStepSuite.scala
+++ b/resource-managers/kubernetes/core/src/test/scala/org/apache/spark/deploy/k8s/features/BasicExecutorFeatureStepSuite.scala
@@ -139,9 +139,7 @@ class BasicExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {
       defaultProfile)
     val executor = step.configurePod(SparkPod.initialPod())
 
-    assert(executor.container.getResources.getLimits.size() === 3)
-    assert(amountAndFormat(executor.container.getResources
-      .getLimits.get("memory")) === "1408Mi")
+    assert(executor.container.getResources.getLimits.size() === 2)
     gpuResources.foreach { case (k8sName, testRInfo) =>
       assert(amountAndFormat(
         executor.container.getResources.getLimits.get(k8sName)) === testRInfo.count)
@@ -164,9 +162,7 @@ class BasicExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {
     // Default memory limit is 1024M + 384M (minimum overhead constant).
     assert(executor.container.getImage === EXECUTOR_IMAGE)
     assert(executor.container.getVolumeMounts.size() == 1)
-    assert(executor.container.getResources.getLimits.size() === 1)
-    assert(amountAndFormat(executor.container.getResources
-      .getLimits.get("memory")) === "1408Mi")
+    assert(executor.container.getResources.getLimits.size() === 0)
 
     // The pod has no node selector, and 1 volume.
     assert(executor.pod.getSpec.getNodeSelector.isEmpty)
@@ -296,8 +292,6 @@ class BasicExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {
 
     assert(amountAndFormat(executor.container.getResources
       .getRequests.get("cpu")) === "4")
-    assert(amountAndFormat(executor.container.getResources
-      .getLimits.get("memory")) === "6144Mi")
   }
 
   test("resourceprofile with gpus") {
@@ -311,12 +305,10 @@ class BasicExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {
     val step = new BasicExecutorFeatureStep(newExecutorConf(), new SecurityManager(baseConf), rp)
     val executor = step.configurePod(SparkPod.initialPod())
 
-    assert(amountAndFormat(executor.container.getResources
-      .getLimits.get("memory")) === "1408Mi")
     assert(amountAndFormat(executor.container.getResources
       .getRequests.get("cpu")) === "2")
 
-    assert(executor.container.getResources.getLimits.size() === 2)
+    assert(executor.container.getResources.getLimits.size() === 1)
     assert(amountAndFormat(executor.container.getResources.getLimits.get("nvidia.com/gpu")) === "2")
   }
 
